# Entendendo o que são containers e o Kubernetes.
### 01.1.	O que é um container?
**Container** é, em português claro, é o agrupamento de uma aplicação junto com suas dependências, que compartilham o **kernel** do sistema operacional do host, ou seja, da máquina (virtual ou física) onde está rodando. Deu para entender?

**Containers** são bem similares às máquinas virtuais, porém mais leves e mais integrados ao sistema operacional da máquina **host**, uma vez que, como já dissemos, compartilha o seu **kernel**, o que proporciona melhor desempenho por conta do gerenciamento único dos recursos.

Na maioria dos casos, a imagem de um **container** é bastante enxuta, havendo somente o necessário para o funcionamento da aplicação, que, quando em execução, possui um pequeno **overhead** se comparada à mesma aplicação rodando nativamente no sistema operacional, grande parte disso por conta do compartilhamento dos recursos com a máquina **host**.

Quando estamos utilizando máquinas virtuais, nós emulamos um novo sistema operacional e virtualizamos todo o seu hardware utilizando mais recursos da máquina **host**, o que não ocorre quando utilizamos **containers**, pois os recursos são compartilhados. O ganho óbvio disso é a capacidade de rodar mais containers em um único host, se comparado com a quantidade que se conseguiria com máquinas virtuais.

A seguir, na figura, podemos notar as diferenças de quando temos aplicações sendo executadas nativamente, máquinas virtuais e por fim em containers. Repare que não é necessário emular um novo sistema operacional quando estamos utilizando containers, diferentemente das máquinas virtuais.

<p align=center><img width="574" height="266" alt="image" src="https://github.com/user-attachments/assets/d03835f3-38b4-4059-995c-f65c375abe1f" /></p>

Outro ponto interessante na utilização de **containers** é a portabilidade. Não importa em qual ambiente você criou o seu container, ele irá rodar em qualquer outro que possua, no caso de Docker, o Docker instalado, seja ele no Linux, MacOS ou Windows. 

Você não precisa se preocupar com suas dependências, está tudo dentro do container. :D

O desenvolvedor consegue, na sua própria máquina, criar uma aplicação em **container** e depois executá-la em um servidor de produção sem nenhum problema de dependência ou algo do tipo -- nem mesmo o bom e velho "engraçado, na minha máquina funciona" escapa, hein?

Lembre-se: na máquina virtual você emula um novo sistema operacional dentro do sistema operacional do host. Já no container você emula somente as aplicações e suas dependências tornando-o portátil.

### 01.2.	O que é um container engine?
O Container Engine é o responsável por gerenciar as imagens e volumes, ele é o responsável por garantir que os recursos utilizados pelos containers estão devidamente isolados, a vida do container, storage, rede, etc.

Até pouco tempo atrás tínhamos somente o Docker para esse papel. Mas hoje já temos diversas opções para se utilizar como Container Engine.

Opções como o Docker, o CRI-O e o Podman são bem conhecidas e preparadas para o ambiente produtivo. O Docker, é o Container Engine mais popular e ele utiliza como Container Runtime o containerd.

### 01.3.	O que é um container engine runtime?
Para que seja possível executar os containers nos nós é necessário ter um Container Runtime instalado em cada um desses nós.

O Container Runtime é o responsável por executar os containers nos nós. Quando você está utilizando ferramentas como Docker ou Podman para executar containers em sua máquina, por exemplo, você está fazendo uso de algum Container Runtime, ou melhor, o seu Container Engine está fazendo uso de algum Container Runtime.

Temos três tipos de Container Runtime:

* **Low-level**: são os Container Runtime que são executados diretamente pelo Kernel, como o runc, o crun e o runsc.  
* **High-level**: são os Container Runtime que são executados por um Container Engine, como o containerd, o CRI-O e o Podman.  
* **Sandbox** e **Virtualized**: são os Container Runtime que são executados por um Container Engine e que são responsáveis por executar containers de forma segura. O tipo Sandbox é executado em unikernels ou utilizando algum proxy para fazer a comunicação com o Kernel. O gVisor é um exemplo de Container Runtime do tipo Sandbox. Já o tipo Virtualized é executado em máquinas virtuais. A performance aqui é um pouco menor do que quando executado nativamente. O Kata Containers é um exemplo de Container Runtime do tipo Virtualized.

### 01.4. O que é OCI?
A OCI é uma organização sem fins lucrativos que tem como objetivo padronizar a criação de containers, para que possam ser executados em qualquer ambiente. A OCI foi fundada em 2015 pela Docker, CoreOS, Google, IBM, Microsoft, Red Hat e VMware e hoje faz parte da Linux Foundation.

O runc, principal projeto desenvolvido pela OCI, é um container runtime de baixo nível amplamente utilizado por diversos Container Engines, incluindo o Docker. Este projeto, totalmente open source, é escrito em Go e seu código fonte pode ser acessado no GitHub.

### 01.5. O que é o Kubernetes?
O Kubernetes (também chamado de K8s) é uma plataforma open source de orquestração de containeres. Ele serve para implantar, gerenciar, escalar e manter aplicações em containeres (geralmente Docker) de forma automática e confiável.

O projeto Kubernetes foi desenvolvido pela Google, em meados de 2014, para atuar como um orquestrador de containeres para a empresa. O Kubernetes (k8s), cujo termo em grego significa “timoeiro”, é um projeto open source que conta com design e desenvolvimento baseados no projeto Borg, que também é da Google. Alguns outros produtos disponíveis no mercado, tais como o Apache Mesos e o Cloud Foundry, também surgiram a partir do projeto Borg.

Como Kubernetes é uma palavra difícil de se pronunciar - e de se escrever - a comunidade simplesmente o apelidou de k8s, seguindo o padrão i18n (a letra "k" seguida por oito letras e o "s" no final), pronunciando-se simplesmente "kates".

**Por que usar o Kubernetes?**  
Manter os aplicativos em containeres em funcionamento pode ser complexo, pois eles geralmente envolvem muitos containeres implantados em computadores diferentes. O Kubernetes fornece uma maneira de agendar e implantar esses containeres, além de dimensioná-los para o estado desejado e gerenciar seus ciclos de vida. Use o Kubernetes para implementar seus aplicativos baseados em containeres de maneira portátil, escalonável e extensível.

* **Tornar as cargas de trabalho portáteis**: Como os aplicativos de container são separados de sua infraestrutura, eles se tornam portáteis quando são executados no Kubernetes. Migre-os de máquinas locais para a produção em ambientes locais, híbridos e entre várias nuvens, tudo isso mantendo a consistência entre ambientes.  
* **Dimensione containeres facilmente**: Defina aplicativos de container complexos e implante-os em um cluster de servidores ou mesmo em vários clusters com o Kubernetes. Conforme o Kubernetes dimensiona os aplicativos de acordo com o estado desejado, ele monitora automaticamente e mantém a integridade do container.  
* **Criar aplicativos mais extensíveis**: Uma grande comunidade de software livre de desenvolvedores e empresas ativamente cria extensões e plug-ins que adicionam recursos como segurança, monitoramento e gerenciamento ao Kubernetes. Além disso, o Programa de Conformidade do Kubernetes Certificado requer cada versão do Kubernetes seja compatível com APIs que facilitam o uso dessas ofertas da comunidade.

### 01.6.  O que são os workers e o control plane do Kubernetes?
**O que são Workers no Kubernetes?**  
No Kubernetes, os workers são as máquinas responsáveis por executar as aplicações que você implanta no cluster.

Um worker é um nó do cluster Kubernetes que:  
* Executa pods;  
* Roda os containeres das aplicações;  
* Se comunica com o control plane;  
* Reporta status (CPU, memória, saúde).  

Ele pode ser uma máquina física, VM ou uma instância em cloud (EC2, VM, etc).  

**O que é o Control Plane no Kubernetes?**  
O Control Plane é responsável por gerenciar o cluster. O Control Plane coordena todas as atividades no seu cluster, como agendamento de aplicativos, manutenção do estado desejado dos aplicativos, dimensionamento de aplicativos e lançamentos de novas atualizações.  

O Control Plane é responsável por:  
* Receber comandos (kubectl, APIs, CI/CD);  
* Manter o estado desejado do cluster;  
* Decidir em qual worker cada pod vai roda;  
* Monitorar a saúde do cluster;  
* Reagir a falhas;  
* Garantir que o estado atual seja o estado desejado.  

### 01.7.  Quais os componentes do control plane do Kubernetes?
Em um control plane, os principais componentes são:

* **etcd**: o etcd é um datastore chave-valor distribuído que o k8s utiliza para armazenar as especificações, status e configurações do cluster. Todos os dados armazenados dentro do etcd são manipulados apenas através da API. Por questões de segurança, o etcd é por padrão executado apenas em nós classificados como control plane no cluster k8s, mas também podem ser executados em clusters externos, específicos para o etcd, por exemplo;

* **Kube API Server**: é um dos principais componentes do k8s. Este componente fornece uma API que utiliza JSON sobre HTTP para comunicação, onde para isto é utilizado principalmente o utilitário kubectl, por parte dos administradores, para a comunicação com os demais nós. Estas comunicações entre componentes são estabelecidas através de requisições REST;

* **Kube scheduler**: o scheduler é responsável por selecionar o nó que irá hospedar um determinado pod (a menor unidade de um cluster k8s - não se preocupe sobre isso por enquanto, nós falaremos mais sobre isso mais tarde) para ser executado. Esta seleção é feita baseando-se na quantidade de recursos disponíveis em cada nó, como também no estado de cada um dos nós do cluster, garantindo assim que os recursos sejam bem distribuídos. Além disso, a seleção dos nós, na qual um ou mais pods serão executados, também pode levar em consideração políticas definidas pelo usuário, tais como afinidade, localização dos dados a serem lidos pelas aplicações, etc;

* **Kube controller manager**: é o controller manager quem garante que o cluster esteja no último estado definido no etcd. Por exemplo: se no etcd um deploy está configurado para possuir dez réplicas de um pod, é o controller manager quem irá verificar se o estado atual do cluster corresponde a este estado e, em caso negativo, procurará conciliar ambos;

### 01.8.  Quais os componentes dos workers do Kubernetes?
Nos workers, os principais componentes são:

* **Kubelet**: o kubelet desempenha o papel de um agente do k8s que é executado nos nós workers. Em cada nó worker deverá existir um agente Kubelet em execução, encarregado de gerenciar efetivamente os pods direcionados pelo controller do cluster dentro dos nós. Para isso, o Kubelet pode iniciar, parar e manter os containeres e os pods em funcionamento seguindo as instruções fornecidas pelo controlador do cluster;

* **Kube-proxy**: age como um proxy e um load balancer. Este componente é responsável por efetuar roteamento de requisições para os pods corretos, como também por cuidar da parte de rede do nó;

### 01.9.  Quais as portas TCP e UDP dos componentes do Kubernetes?
Abaixo, as portas de comunicação que o control plane utiliza:
<p align=center><img width="579" height="124" alt="image" src="https://github.com/user-attachments/assets/6877b5d6-6a60-4244-b8f2-f9cb30e1ef90" /></p>

**Obs:** Toda porta marcada por * é customizável, você precisa se certificar que a porta alterada também esteja aberta.

Abaixo, as portas de comunicação que os workers utilizam:
<p align=center><img width="581" height="63" alt="image" src="https://github.com/user-attachments/assets/e20bc003-d44c-44de-9ce6-5986934e92d8" /></p>

### 01.10.	Introdução a pods, replica sets, deployments e services.
É importante saber que a forma como o k8s gerencia os containeres é ligeiramente diferente de outros orquestradores, como o Docker Swarm, sobretudo devido ao fato de que ele não trata os containeres diretamente, mas sim através de pods. Vamos conhecer alguns dos principais conceitos que envolvem o k8s a seguir:

* **Pod**: é o menor objeto do k8s. Como dito anteriormente, o k8s não trabalha com os containeres diretamente, mas organiza-os dentro de pods, que são abstrações que dividem os mesmos recursos, como endereços, volumes, ciclos de CPU e memória. Um pod pode possuir vários containeres;

* **Deployment**: em termos simples, um Deployment no Kubernetes é um recurso que define o estado desejado de uma aplicação em execução. Ele permite que você descreva, atualize e gerencie aplicações de forma declarativa. Ao utilizar Deployments, você não precisa se preocupar com os detalhes da implementação, pois o Kubernetes cuidará automaticamente do processo de implantação e atualização;

* **ReplicaSets**: é um objeto responsável por garantir a quantidade de pods em execução no nó;

* **Services**: é uma forma de você expor a comunicação através de um ClusterIP, NodePort ou LoadBalancer para distribuir as requisições entre os diversos Pods daquele Deployment. Funciona como um balanceador de carga.

### 01.11.	Entendendo e instalando o kubectl.
A ferramenta de linha de comando do Kubernetes, kubectl, permite executar comandos em clusters do Kubernetes. Você pode usar o kubectl para implantar aplicativos, inspecionar e gerenciar recursos do cluster e visualizar logs. Para obter mais informações, incluindo uma lista completa das operações do kubectl, consulte a **[documentação de referência](https://kubernetes.io/docs/reference/kubectl/).**

**Para instalar o kubectl no Linux, execute os passos abaixo:**  
* **Baixe o kubectl**: curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

* **Dê a permissão de execução**: chmod +x kubectl  
* **Mova o kubectl para o PATH**: mv kubectl /usr/local/bin  
* **Ver a versão do kubectl**: kubectl version
<p align=center><img width="285" height="49" alt="image" src="https://github.com/user-attachments/assets/f9c055af-8eaf-4790-8e4c-631f11500f26" /></p>

### 01.12.	Criando o nosso primeiro cluster com o kind.
O kind é uma ferramenta para executar clusters Kubernetes locais usando "nós" de containeres Docker. O kind foi projetado principalmente para testar o próprio Kubernetes, mas também pode ser usado para desenvolvimento local ou integração contínua (CI).

Siga os passos abaixo para instalar o kind no Linux:  
* **Baixe o kind**: [ $(uname -m) = x86_64 ] && curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.31.0/kind-linux-amd64  

* **Dê a permissão de execução**: chmod +x kind
* **Mova o kubectl para o PATH**: sudo mv kind /usr/local/bin  
* **Ver a versão do kind**: kind version

Para executar o kind, devemos ter o Docker instalado na máquina...  
* **Execute o script de instalação**: curl -fsSL https://get.docker.com | bash  

Caso a instalação do Docker não funcione via script, acesse a página de instalação do Docker para outros sistemas: https://docs.docker.com/engine/install/  

**Trabalhando com kind.**  
Abaixo, os principais comandos para trabalhar com o kind:  
* **Para criar um cluster**: kind create cluster  
* No momento da criação, use a flag **--name** para colocar um nome no cluster.   
* **Para ver os nodes configurados**: kubectl get nodes  
* **Ver informações do cluster**: kubectl cluster-info --context kind-kind  
* **Fazer um dump das informações**: kubectl cluster-info dump  
* **Deletar o cluster**: kind delete cluster  
* **Ver a lista de clusters existentes**: kind get clusters  

**Criando um cluster com vários nós.**  
Em particular, muitos usuários podem estar interessados em clusters com múltiplos nós. Crie o arquivo de configuração **cluster.yaml** com o conteúdo abaixo:  
<p align="center"><img width="277" height="104" alt="image" src="https://github.com/user-attachments/assets/34adb1db-e9d3-4ba9-b81a-8ec40fd0ef4c" /></p>

* **Após isso, aplique a configuração**: kind create cluster --config cluster.yaml --name cluster1

Após a criação do cluster, execute **kubectl get nodes** para visualizar o cluster criado.  
<p align="center"><img width="528" height="68" alt="image" src="https://github.com/user-attachments/assets/846d214a-649b-4e76-a69b-2e0d9395e7b9" /></p>

### 01.13.	Primeiros passos no Kubernetes com o kubectl.  
Para buscar informações no Kubernetes, sempre será usado o comando **kubectl get**. Veja abaixo mais informações:

* **Ver informações de nodes**: kubectl get nodes  
* **Ver informações dos namespaces**: kubectl get namespaces  
* **Ver informações dos deployments**: kubectl get deployments  
* **Ver informações dos services**: kubectl get services  
* **Ver informações dos replicaset**: kubectl get replicaset  
* **Ver informações dos pods**: kubectl get pods  
* **Ver info de pod de um namespace especifico**: kubectl get pods -n kube-system  
* **Ver os pods com mais detalhes ainda**: kubectl get pods -n kube-system -o wide  
* **Para ver informações dos pods pela label**: kubecl get pods -l  
* **Ver informações de pods do cluster todo**: kubectl get pods -A  

**Obs:** os parâmetros **-A** e **-o wide** podem ser utilizados em qualquer comando da família **get**. Veja abaixo outros parâmetros:  
* **-A** apresenta informações de todos os namespaces.  
* **-o wide**: significa output wide, ou seja, saída estendida. Ele faz com que o comando mostre mais colunas de informação, além do resumo padrão.  
* Inclua **-w** para ficar acompanhando a implantação de novos recursos.  

**kubectl run**
O **kubectl run** é um comando do Kubernetes usado para criar e executar rapidamente um Pod (ou, em versões antigas, outros recursos) a partir de uma imagem de container.

Hoje ele é mais usado para testes rápidos, debug e execuções pontuais, não para workloads permanentes.  

**Para criar um pod com nginx, execute**: kubectl run --image nginx --port 80 nginx  
* O parâmetro **--image** informa qual imagem será utilizada.  
* O parâmetro **--port** expõe a porta 80.

**kubectl exec**  
O **kubectl exec** é um comando do Kubernetes usado para executar comandos dentro de um container que já está rodando em um Pod.  
Ele é muito utilizado para debug, troubleshooting e inspeção de aplicações em execução.  

**Para acessar um pod com o bash, execute**: kubectl exec -ti nginx -- bash  
* O parâmetro **t (tty)** faz com que o shell se comporte como um terminal real.  
* O parâmetro **i** mantém a entrada padrão aberta e permite digitar comandos e enviar input para o conteiner (ou pod).

**kubectl expose**  
O **kubectl expose** é um comando do Kubernetes usado para criar um Service a partir de um recurso existente, tornando um Pod, Deployment, ReplicaSet ou StatefulSet acessível na rede do cluster (ou fora dele, dependendo do tipo de Service).

Abaixo, comandos do kubectl expose:  
* **Para criar um service, execute**: kubectl expose pods nginx  
* **Criar um service do tipo NodePort**: kubectl expose pods nginx --type NodePort  

**kubectl delete**  
O comando **kubectl delete** deleta recursos no Kubernetes.  
* **Para deletar um pod, execute**: kubectl delete pods nginx  
* **Forçar a remoção de um pod**: k delete pod **nginx** --grace-period=0 --force  

**Autocomplete para o Kubernetes.**  
É possível, executando o kubectl, configurar o autocomplete para comandos... para isso, siga os passos abaixo:  

* **Confirme que o bash-completion está instalado** : sudo apt install bash-completion
* **Configure o autocomplete no bash_profile**: echo "source '$HOME/.kube/completion.bash.inc'" >> $HOME/.bash_profile
* **Carregue essa configuração**: source $HOME/.bash_profile

**Alias**  
É interessante incluir alguns alias no $HOME/.bash_profile, como por exemplo:  
* alias **k="kubectl"**

### 01.14. Conhecendo o YAML e o kubectl com dry-run.  
No Kubernetes, **dry-run** no kubectl é um modo de simulação: ele mostra o que seria feito, sem aplicar nenhuma alteração real no cluster. É muito usado para validar manifests, gerar YAML e evitar erros antes de criar/alterar recursos.  

**Execução do kubectl run com dry-run:** kubectl run girus --image alpine --dry-run=client  

* Incluindo **-o yaml**, os parâmetros do recurso que seria criado são apresentados na tela no formato YAML.  
* Direcione a saída desse comando para um arquivo com **>** para criar um arquivo YAML contendo essa configuração.  

**Abaixo, o comando para criação de um arquivo YAML com a configuração de pod.**  
kubectl run girus --image alpine --dry-run=client -o yaml > pod.yaml

**Para aplicar a configuração criada nesse arquivo, execute:** kubectl apply -f pod.yaml  
<p align="center"><img width="423" height="36" alt="image" src="https://github.com/user-attachments/assets/c14cf3ee-ca2c-49a1-9611-b46626814b98" /></p>
