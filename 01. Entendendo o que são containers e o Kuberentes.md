# Entendendo o que são containers e o Kubernetes.
### 01.1.	O que é um container?
**Container** é, em português claro, é o agrupamento de uma aplicação junto com suas dependências, que compartilham o **kernel** do sistema operacional do host, ou seja, da máquina (virtual ou física) onde está rodando. Deu para entender?

**Containers** são bem similares às máquinas virtuais, porém mais leves e mais integrados ao sistema operacional da máquina **host**, uma vez que, como já dissemos, compartilha o seu **kernel**, o que proporciona melhor desempenho por conta do gerenciamento único dos recursos.

Na maioria dos casos, a imagem de um **container** é bastante enxuta, havendo somente o necessário para o funcionamento da aplicação, que, quando em execução, possui um pequeno **overhead** se comparada à mesma aplicação rodando nativamente no sistema operacional, grande parte disso por conta do compartilhamento dos recursos com a máquina **host**.

Quando estamos utilizando máquinas virtuais, nós emulamos um novo sistema operacional e virtualizamos todo o seu hardware utilizando mais recursos da máquina **host**, o que não ocorre quando utilizamos **containers**, pois os recursos são compartilhados. O ganho óbvio disso é a capacidade de rodar mais containers em um único host, se comparado com a quantidade que se conseguiria com máquinas virtuais.

A seguir, na figura, podemos notar as diferenças de quando temos aplicações sendo executadas nativamente, máquinas virtuais e por fim em containers. Repare que não é necessário emular um novo sistema operacional quando estamos utilizando containers, diferentemente das máquinas virtuais.

<p align=center><img width="574" height="266" alt="image" src="https://github.com/user-attachments/assets/d03835f3-38b4-4059-995c-f65c375abe1f" /></p>

Outro ponto interessante na utilização de **containers** é a portabilidade. Não importa em qual ambiente você criou o seu container, ele irá rodar em qualquer outro que possua, no caso de Docker, o Docker instalado, seja ele no Linux, MacOS ou Windows. 

Você não precisa se preocupar com suas dependências, está tudo dentro do container. :D

O desenvolvedor consegue, na sua própria máquina, criar uma aplicação em **container** e depois executá-la em um servidor de produção sem nenhum problema de dependência ou algo do tipo -- nem mesmo o bom e velho "engraçado, na minha máquina funciona" escapa, hein?

Lembre-se: na máquina virtual você emula um novo sistema operacional dentro do sistema operacional do host. Já no container você emula somente as aplicações e suas dependências tornando-o portátil.

### 01.2.	O que é um container engine?
O Container Engine é o responsável por gerenciar as imagens e volumes, ele é o responsável por garantir que os recursos utilizados pelos containers estão devidamente isolados, a vida do container, storage, rede, etc.

Até pouco tempo atrás tínhamos somente o Docker para esse papel. Mas hoje já temos diversas opções para se utilizar como Container Engine.

Opções como o Docker, o CRI-O e o Podman são bem conhecidas e preparadas para o ambiente produtivo. O Docker, é o Container Engine mais popular e ele utiliza como Container Runtime o containerd.

### 01.3.	O que é um container engine runtime?
Para que seja possível executar os containers nos nós é necessário ter um Container Runtime instalado em cada um desses nós.

O Container Runtime é o responsável por executar os containers nos nós. Quando você está utilizando ferramentas como Docker ou Podman para executar containers em sua máquina, por exemplo, você está fazendo uso de algum Container Runtime, ou melhor, o seu Container Engine está fazendo uso de algum Container Runtime.

Temos três tipos de Container Runtime:

* **Low-level**: são os Container Runtime que são executados diretamente pelo Kernel, como o runc, o crun e o runsc.  
* **High-level**: são os Container Runtime que são executados por um Container Engine, como o containerd, o CRI-O e o Podman.  
* **Sandbox** e **Virtualized**: são os Container Runtime que são executados por um Container Engine e que são responsáveis por executar containers de forma segura. O tipo Sandbox é executado em unikernels ou utilizando algum proxy para fazer a comunicação com o Kernel. O gVisor é um exemplo de Container Runtime do tipo Sandbox. Já o tipo Virtualized é executado em máquinas virtuais. A performance aqui é um pouco menor do que quando executado nativamente. O Kata Containers é um exemplo de Container Runtime do tipo Virtualized.

### 01.4. O que é OCI?
A OCI é uma organização sem fins lucrativos que tem como objetivo padronizar a criação de containers, para que possam ser executados em qualquer ambiente. A OCI foi fundada em 2015 pela Docker, CoreOS, Google, IBM, Microsoft, Red Hat e VMware e hoje faz parte da Linux Foundation.

O runc, principal projeto desenvolvido pela OCI, é um container runtime de baixo nível amplamente utilizado por diversos Container Engines, incluindo o Docker. Este projeto, totalmente open source, é escrito em Go e seu código fonte pode ser acessado no GitHub.

### 01.5. O que é o Kubernetes?
O Kubernetes (também chamado de K8s) é uma plataforma open source de orquestração de containeres. Ele serve para implantar, gerenciar, escalar e manter aplicações em containeres (geralmente Docker) de forma automática e confiável.

O projeto Kubernetes foi desenvolvido pela Google, em meados de 2014, para atuar como um orquestrador de containeres para a empresa. O Kubernetes (k8s), cujo termo em grego significa “timoeiro”, é um projeto open source que conta com design e desenvolvimento baseados no projeto Borg, que também é da Google. Alguns outros produtos disponíveis no mercado, tais como o Apache Mesos e o Cloud Foundry, também surgiram a partir do projeto Borg.

Como Kubernetes é uma palavra difícil de se pronunciar - e de se escrever - a comunidade simplesmente o apelidou de k8s, seguindo o padrão i18n (a letra "k" seguida por oito letras e o "s" no final), pronunciando-se simplesmente "kates".

**Por que usar o Kubernetes?**  
Manter os aplicativos em containeres em funcionamento pode ser complexo, pois eles geralmente envolvem muitos containeres implantados em computadores diferentes. O Kubernetes fornece uma maneira de agendar e implantar esses containeres, além de dimensioná-los para o estado desejado e gerenciar seus ciclos de vida. Use o Kubernetes para implementar seus aplicativos baseados em containeres de maneira portátil, escalonável e extensível.

* **Tornar as cargas de trabalho portáteis**: Como os aplicativos de container são separados de sua infraestrutura, eles se tornam portáteis quando são executados no Kubernetes. Migre-os de máquinas locais para a produção em ambientes locais, híbridos e entre várias nuvens, tudo isso mantendo a consistência entre ambientes.  
* **Dimensione containeres facilmente**: Defina aplicativos de container complexos e implante-os em um cluster de servidores ou mesmo em vários clusters com o Kubernetes. Conforme o Kubernetes dimensiona os aplicativos de acordo com o estado desejado, ele monitora automaticamente e mantém a integridade do container.  
* **Criar aplicativos mais extensíveis**: Uma grande comunidade de software livre de desenvolvedores e empresas ativamente cria extensões e plug-ins que adicionam recursos como segurança, monitoramento e gerenciamento ao Kubernetes. Além disso, o Programa de Conformidade do Kubernetes Certificado requer cada versão do Kubernetes seja compatível com APIs que facilitam o uso dessas ofertas da comunidade.

### 01.6.  O que são os workers e o control plane do Kubernetes?
**O que são Workers no Kubernetes?**  
No Kubernetes, os workers são as máquinas responsáveis por executar as aplicações que você implanta no cluster.

Um worker é um nó do cluster Kubernetes que:  
* Executa pods;  
* Roda os containeres das aplicações;  
* Se comunica com o control plane;  
* Reporta status (CPU, memória, saúde).  

Ele pode ser uma máquina física, VM ou uma instância em cloud (EC2, VM, etc).  

**O que é o Control Plane no Kubernetes?**  
O Control Plane é responsável por gerenciar o cluster. O Control Plane coordena todas as atividades no seu cluster, como agendamento de aplicativos, manutenção do estado desejado dos aplicativos, dimensionamento de aplicativos e lançamentos de novas atualizações.  

O Control Plane é responsável por:  
* Receber comandos (kubectl, APIs, CI/CD);  
* Manter o estado desejado do cluster;  
* Decidir em qual worker cada pod vai roda;  
* Monitorar a saúde do cluster;  
* Reagir a falhas;  
* Garantir que o estado atual seja o estado desejado.  



